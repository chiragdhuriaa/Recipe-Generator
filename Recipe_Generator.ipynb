{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"saldenisov/recipenlg\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY2mwEMI9S1s",
        "outputId": "7f48e563-bcdf-401a-c5b8-5b6edfa8bb20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/saldenisov/recipenlg/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "hei3ff2R-dot"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_kaggle_downloads = '/root/.cache/kagglehub/datasets/saldenisov/recipenlg/versions/1/dataset'  # Common path for Kaggle datasets\n",
        "print(os.listdir(path_to_kaggle_downloads))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEfzZr079dh_",
        "outputId": "1fe80533-50c3-46f6-8840-a93703c268ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['full_dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/root/.cache/kagglehub/datasets/saldenisov/recipenlg/versions/1/dataset\"\n",
        "\n",
        "os.listdir(dataset_path)\n",
        "\n",
        "df = pd.read_csv(os.path.join(dataset_path, 'full_dataset.csv'))\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMj_-vAw-h1j",
        "outputId": "e3940833-c73d-49ac-9b25-01147e595d5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                  title  \\\n",
            "0           0    No-Bake Nut Cookies   \n",
            "1           1  Jewell Ball'S Chicken   \n",
            "2           2            Creamy Corn   \n",
            "3           3          Chicken Funny   \n",
            "4           4   Reeses Cups(Candy)     \n",
            "\n",
            "                                         ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
            "2  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "3  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
            "4  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "\n",
            "                                          directions  \\\n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
            "1  [\"Place chipped beef on bottom of baking dish....   \n",
            "2  [\"In a slow cooker, combine all ingredients. C...   \n",
            "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
            "4  [\"Combine first four ingredients and press in ...   \n",
            "\n",
            "                                              link    source  \\\n",
            "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
            "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
            "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
            "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
            "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
            "\n",
            "                                                 NER  \n",
            "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
            "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
            "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
            "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
            "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(df.head())\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaLthYBd-wrX",
        "outputId": "f6e5c995-bb5e-45fa-ef72-716ed39b55df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2231142 entries, 0 to 2231141\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Dtype \n",
            "---  ------       ----- \n",
            " 0   Unnamed: 0   int64 \n",
            " 1   title        object\n",
            " 2   ingredients  object\n",
            " 3   directions   object\n",
            " 4   link         object\n",
            " 5   source       object\n",
            " 6   NER          object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 119.2+ MB\n",
            "None\n",
            "   Unnamed: 0                  title  \\\n",
            "0           0    No-Bake Nut Cookies   \n",
            "1           1  Jewell Ball'S Chicken   \n",
            "2           2            Creamy Corn   \n",
            "3           3          Chicken Funny   \n",
            "4           4   Reeses Cups(Candy)     \n",
            "\n",
            "                                         ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
            "2  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "3  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
            "4  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "\n",
            "                                          directions  \\\n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
            "1  [\"Place chipped beef on bottom of baking dish....   \n",
            "2  [\"In a slow cooker, combine all ingredients. C...   \n",
            "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
            "4  [\"Combine first four ingredients and press in ...   \n",
            "\n",
            "                                              link    source  \\\n",
            "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
            "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
            "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
            "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
            "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
            "\n",
            "                                                 NER  \n",
            "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...  \n",
            "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...  \n",
            "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...  \n",
            "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...  \n",
            "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...  \n",
            "Index(['Unnamed: 0', 'title', 'ingredients', 'directions', 'link', 'source',\n",
            "       'NER'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    df['ingredients'] = df['ingredients'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").replace(\",\", \", \"))\n",
        "    df['directions'] = df['directions'].str.lower().str.strip()\n",
        "    df['title'] = df['title'].str.lower().str.strip()\n",
        "\n",
        "    if 'dietary_restriction' in df.columns:\n",
        "        df['dietary_restriction'] = df['dietary_restriction'].str.lower().str.strip()\n",
        "    else:\n",
        "        df['dietary_restriction'] = ''\n",
        "    return df\n",
        "\n",
        "df = preprocess_data(df)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peb2iiCx-7vP",
        "outputId": "5af9b0ef-5795-4bda-d523-471a7f7816d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                  title  \\\n",
            "0           0    no-bake nut cookies   \n",
            "1           1  jewell ball's chicken   \n",
            "2           2            creamy corn   \n",
            "3           3          chicken funny   \n",
            "4           4     reeses cups(candy)   \n",
            "\n",
            "                                         ingredients  \\\n",
            "0  \"1 c. firmly packed brown sugar\",  \"1/2 c. eva...   \n",
            "1  \"1 small jar chipped beef,  cut up\",  \"4 boned...   \n",
            "2  \"2 (16 oz.) pkg. frozen corn\",  \"1 (8 oz.) pkg...   \n",
            "3  \"1 large whole chicken\",  \"2 (10 1/2 oz.) cans...   \n",
            "4  \"1 c. peanut butter\",  \"3/4 c. graham cracker ...   \n",
            "\n",
            "                                          directions  \\\n",
            "0  [\"in a heavy 2-quart saucepan, mix brown sugar...   \n",
            "1  [\"place chipped beef on bottom of baking dish....   \n",
            "2  [\"in a slow cooker, combine all ingredients. c...   \n",
            "3  [\"boil and debone chicken.\", \"put bite size pi...   \n",
            "4  [\"combine first four ingredients and press in ...   \n",
            "\n",
            "                                              link    source  \\\n",
            "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
            "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
            "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
            "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
            "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
            "\n",
            "                                                 NER dietary_restriction  \n",
            "0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...                      \n",
            "1  [\"beef\", \"chicken breasts\", \"cream of mushroom...                      \n",
            "2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...                      \n",
            "3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...                      \n",
            "4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eLwB92gh_Ijq",
        "outputId": "1e6f2b95-13e0-4216-fd42-64f285661cbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "zMgNg9lSCJE-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', use_fast=True)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTqttsx3_4tE",
        "outputId": "893e83e9-61b5-4237-db0b-0ce4534fa4a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(df['directions'].tolist(), truncation=True, padding=True, max_length=256)\n",
        "\n",
        "class RecipeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "train_dataset = RecipeDataset(train_encodings)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "y4skSVnw_MQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "wKnunYZmCreN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe(dietary_restriction, cuisine_type, prompt):\n",
        "    input_text = f\"{dietary_restriction} {cuisine_type} recipe: {prompt}\"\n",
        "    inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    outputs = model.generate(inputs, max_length=200, num_return_sequences=1)\n",
        "    recipe = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return recipe\n",
        "\n",
        "dietary_restriction = \"non veg\"\n",
        "cuisine_type = \"french\"\n",
        "prompt = \"pasta with cheese\"\n",
        "print(generate_recipe(dietary_restriction, cuisine_type, prompt))"
      ],
      "metadata": {
        "id": "-djeAwTi_UDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./my_recipe_model')\n",
        "tokenizer.save_pretrained('./my_recipe_model')"
      ],
      "metadata": {
        "id": "p7TO08WaCv79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}